\documentclass[journal, a4paper]{IEEEtran}

% some very useful LaTeX packages include:

%\usepackage{cite}      % Written by Donald Arseneau
% * <yueguo@iu.edu> 2018-09-01T13:39:33.474Z:
%
% ^.
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/

\usepackage{graphicx}   % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/

%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

\usepackage{url}        % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}    % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/



% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% V1.6 of IEEEtran contains the IEEEeqnarray family of commands that can
% be used to generate multiline equations as well as matrices, tables, etc.

% Also of notable interest:
% Scott Pakin's eqparbox package for creating (automatically sized) equal
% width boxes. Available 
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/eqparbox/

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
\usepackage{listings}

% Your document starts here!
\begin{document}

% Define document title and author
	\title{E511-Signal Processing-Final Project}
	\author{Jonathan Branam, Jamie Israel, Jinju(Hellen) Jiang}
	\date{December, 13 2018}
	\maketitle
%
% ^.
% Write abstract here
\begin{abstract}
In this project we evaluated and implemented state of the art techniques to solve the monaural speech separation (diarization) problem using a variety of approached. We investigated classification, masking, and deep learning approaches to separate a generated set of mixed speech recordings.
\end{abstract}

% Each section begins with a \section{title} command
\section{Introduction}
There have been several recent developments in the use of deep learning to perform speaker diarization, or separation of multiple speech signals from a single source into separate homogeneous signals representing each individual speaker. This task is particularly challenging where the input is monophonic, there is no control over environmental conditions, the number of speakers is unknown and there are no samples of the speakers from which to train. Using the CSR-I(WSJ0) Complete dataset\cite{WSJintro}, we tested several algorithms for accomplishing monaural speech separation including classification (KMeans), various masking approaches (NMF, Ideal Ratio Mask[IRM], and complex Ideal Ratio Mask [cIRM]), and permutation-based deep learning approaches (Permutation Invariant Training [PIT] and utterance-level Permutation Invariant Training [uPIT]).

The motivating application is to separate agent and customer utterances from call center recordings, which involve short duration speech with occasional cross talk and at least one unknown speaker.

\section{Literature Review}

\subsection{Jamie's Lit Review}


\subsection{Deep Learning Approaches}

A seminal paper in applying deep learning to the task of speaker diarization was the Deep Clustering \cite{DBLP:journals/corr/HersheyCRW15} approach proposed by Hershey, et. al. They divided the task of separating source signals into two steps. The first step is to use a deep neural network to learn a set of embeddings that produce a class-independent, low-rank approximation of the sources. These embeddings are trained to minimize the distance between embeddings in the same partition while maximizing the distances between embeddings in different partitions. The partitions used in their technique do not include class labels so the model does not assign a particular class to each embedding. The resulting embeddings can then be separated using simple clustering algorithms such as $k$-means. This is in contrast to previous work that relies on \textit{spectral clustering} for segmentation which uses local affinity measures to optimize an objective function using spectral decomposition. The approach of Hershey, et. al. is typical in current research for deep learning: rather than using a complicated set of specially designed features the deep clustering approach uses a deep neural network to discover the best features for producing the desired partitions.

Results:



\section{Dataset Preparation}
\subsection{CSR-I(WSJ0) Complete}
For purposes of comparison with existing scholarship, each approach was developed based on the WSJ0 dataset, a corpus of Wall Street Journal text data organized by speakers.






\subsection{WSJ0-mix}

 
Developed based on...\cite{WSJmix}.


\section{Speech Separation Algorithms}
\subsection{KMeans}
The technique of speaker diarization relies on a big pipeline with following steps:
\begin{itemize}
    \item Feature Extraction
    \item Speaker segmentation
    \item Speaker Clustering
    \item Evaluation
\end{itemize}
\subsubsection{Feature Extraction}
In this project, we used 3 approaches to extract features:
\begin{itemize}
    \item A chroma vector (Wikipedia) (FMP, p. 123) is a typically a 12-element feature vector indicating how much energy of each pitch class, {C, C\#, D, D\#, E, ..., B}, is present in the signal. Then use mean of each element as one of input for clustering.
    \item The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features  which concisely describe the overall shape of a spectral envelope. In this case, mfcc computed 13 MFCCs.The very first MFCC, the 0th coefficient, does not convey information relevant to the overall shape of the spectrum. It only conveys a constant offset, i.e. adding a constant value to the entire spectrum. Therefore, here I discard the first MFCC, then I scale the MFCCs such that each coefficient dimension has zero mean and unit variance.Then use mean of MFCCS as one part of input for clustering.
    \item We divide the audio signal into smaller frames. In smaller time scales audio signals are statistically unchanged. Then for each smaller frames we compute the power spectrum of the signal, and use it as the third part of input for clustering.
\end{itemize}
\subsubsection{Speaker segmentation}\cite{Segmentation} Speaker segmentation which is also known as acoustic change detection aims to detect speaker change such that each contiguous segment corresponds to single speaker only. To find if the two segments correspond to same speaker we have to define some notion of distance metric. In this case, I skipped this step and used the features extrated from above steps as input for kmeans clustering.
\subsubsection{Kmeans Clustering}
Since we knew that the audio from call center is the conversation between 2 speakers(customer service and customer), we set k=2 for kmeans clustering.\\
here it is the results for speaker diarization.
\begin{figure}[h!]
    \centering  
     \caption{\label{Fig:speaker diarization}2 speakers diarization}  
    \includegraphics[width=0.4\textwidth]{kmeans01.png} 
\end{figure}

\begin{figure}[h!]
    \centering  
     \caption{\label{Fig:speaker diarization}2 speakers diarization}  
    \includegraphics[width=0.4\textwidth]{kmeans02.png}
\end{figure}
\subsubsection{Evaluation\cite{Segmentation}}Diarization Error Rate (DER) is used for evaluation of automatic speech recognition system.Contribution to DER comes from three factors namely, Missed speech rate (MSR), False alarm speech rate (FASR) and Speaker Error. When a speech is labeled as non-speech then that error comes under MSR. FASR is when a non- speech is detected as a speech segment. Speaker error is contributed due to speaker clustering and segmentation. This kind of error can be caused if a speaker change is not detected, oversegmentation, erroneously clustered. Sum of all three errors contribute to the DER.\\
In this case, we don't have any labeled data to calculate the training error, we just simply used human ears to justify whether the diarization was good or not. For some training data, it works well, but some training data, it performed really bad. 

\subsection{NMF, IRM and cIRM}
Nonnegative matrix factorization (NMF) is used to represent high-dminesional data as the product of two matrices (typically referenced as \textit{W} and \textit{H}). In the case of an audio signal, these matrices can be viewed as a representation of the signal's frequency spectrum (\textit{W}) and the corresponding activations (\textit{H}).

To perform NMF, we transformed isolated audio samples of two speakers (speaker 1 and speaker 2) to a frequency-time representation using short-time Fourier transform (STFT) before decomposing each signal using the following iterative update rules:
\newline

$W = W \bigodot \frac{\frac{X}{WH}H^T}{1{FxT}H^T}$ \hspace{1cm} $H = H \bigodot \frac{W^T\frac{X}{WH}}{W^T1^{FxT}}$
\newline

Using the frequency matrices associated with the sample from each speaker, a new set of activations (\textit{W}) was generated from the mixed signal composed of both individual samples. A magnitude masking matrix, reflecting the magnitudes associated with the frequency representation for each speaker at each time frame, was generated using this new set of activations and the following formula:

\begin{center}
$W_{S1}H_{(1:30,:)}$

\rule[1pt]{100pt}{.4pt}

$W_{S1}H_{(1:30,:)}+W_{S2}H_{(31:60,:)}  $

\end{center}


\begin{flushleft}
where S1 is the basis vector associated with the speaker 1 audio sample, S2 is the basis vector associated with the speaker 2 audio sample and H is the activation matrix generated from the combined speaker 1 and speaker 2 basis vectors.\cite{ClassNMF}
\end{flushleft}

Using the STFT of a single speaker audio sample (speaker 1) and the STFT of the mixed audio sample that included speaker 1 [Figure 1], an IRM was generated based on the formula:
\begin{center}
$S_{(t,f)}^2$

\rule[1pt]{40pt}{.4pt}

$S_{(t,f)}^2 + N_{(t,f)}^2  $

\end{center}


\begin{flushleft}

where S is the STFT generated from the isolated speaker 1 audio signal and N is the STFT generated fromm the mixed audio signal that included the same audio sample of speaker 1.\cite{DBLP:journals/corr/abs-1708-07524}

\end{flushleft}

\begin{figure}[h!]
    \centering  
     \caption{\label{Fig:Spectrogram of isolated amd mixed audio sample from speaker 1}Spectrogram of isolated amd mixed audio sample from speaker 1}  
    \includegraphics[width=0.4\textwidth]{cIRM_same.png}  
\end{figure}

Similarly, a cIRM was generated from the audio sample of speaker 1 and the same mixed audio sample using the formula:

\begin{center}
$Y_r S_r + Y_i S_i \hspace{1.6cm} Y_r S_i - Y_i S_r$

\rule[3pt]{45pt}{.4pt} \hspace{.3cm} + \hspace{.4cm} \textit{i} \hspace{.1cm} \rule[3pt]{45pt}{.4pt}


$Y_r^2 + Y_i^2  \hspace{2.0cm} Y_r^2 + Y_i^2$

\end{center}

\begin{flushleft}
where S is the complex STFT representation generated from the isolated speaker 1 audio signal and Y is the complex STFT generated form the mixed audio signal that included the same audio sample of speaker 1.\cite{DBLP:journals/corr/abs-1708-07524}
\end{flushleft}

\subsection{PIT and uPIT}

..
.... Add text here....


\section{Results}

\subsection{Masking Methods}

With the NMF method, we were unable to generate a substantial separation between the original isolated signal and the mixed audio. Both IMR approaches produced substantially better results with the cIMR method proving to be the best method for this type of separation on a consistent basis [Figure 2].


\begin{figure}[h!]
    \centering  
     \caption{\label{Fig:Comparison of Average SNR for Masking Methods 1}Comparison of Average SNR for Masking Methods}  
    \includegraphics[width=0.3\textwidth]{Mask_Res.png}  
\end{figure}


\section{Conclusion}
...
\newline 
% Now we need a bibliography:

\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{report} % Entries are in the "refs.bib" file


% Your document ends here!
\end{document}
